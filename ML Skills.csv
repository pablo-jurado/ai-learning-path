Subdomain,Description,,,,,,,,,
Core Mathematics,,,,,,,,,,
Data Preparation & Feature Engineering,,,,,,,,,,
Model Development,,,,,,,,,,
Model Evaluation & Diagnostics,,,,,,,,,,
Model Optimization & Tuning,,,,,,,,,,
"Productionalization, Operation, & Model Lifecycle",,,,,,,,,,
Programming & Libraries for ML,,,,,,,,,,
ML Systems & Scalability,,,,,,,,,,
Use Cases & Application Design,,,,,,,,,,
ML Project Management,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
CHANNEL: Machine Learning,,,,,,,,,,
Subdomain,Skill,Beginner,Novice,Competent,Proficient,Expert,,,,
Core Mathematics,Linear Algebra,Has heard of concepts like matrices or vectors but lacks working understanding. Cannot yet apply them to ML.,"Understands basic matrix operations (addition, multiplication, transposition) and concepts like dot products. Can follow tutorials using matrix math in ML libraries.","Applies eigenvectors, SVD, and vector spaces in practice (e.g. PCA, embeddings). Can explain why these methods are used in ML.",Understands and implements algorithms that rely heavily on linear algebra. Can debug dimensionality errors and optimize computation using matrix properties. ,Teaches and mentors others in applied linear algebra. Can design novel models or transformations informed by deep understanding of vector space geometry and tensor algebra.,,,,
,Calculus,Aware that ML involves derivatives but does not understand how they are used.,Understands the role of derivatives and gradients in training (e.g. gradient descent). Can compute simple partial derivatives.,"Applies multivariable calculus in backpropagation. Understands Jacobians, Hessians, and their relevance to optimization.",Interprets and manipulates higher-order derivatives in custom training loops or research settings. Uses calculus for model introspection and regularization.,Develops new training techniques or architectures informed by calculus. Guides others in understanding theoretical underpinnings of differentiable models.,,,,
,Probability & Statistics,Recognizes that ML involves chance and randomness but cannot define probability distributions or statistical terms.,"Understands basic distributions (e.g. normal, binomial), descriptive stats (mean, variance), and basic hypothesis testing.","Uses Bayes' theorem, likelihoods, priors, and confidence intervals in applied ML. Understands randomness in model behavior.","Builds and evaluates probabilistic models (e.g. Naive Bayes, Bayesian networks). Understands uncertainty quantification and statistical inference.",Leads probabilistic modeling efforts. Trains others in statistical thinking and probabilistic programming. Challenges and refines assumptions behind statistical methods in ML.,,,,
,Optimization Techniques,"Has heard of optimization in ML (e.g., loss minimization), but cannot explain how it works.","Understands gradient descent and basic tuning (e.g., learning rate, batch size). Can experiment with optimizers like SGD and Adam.","Applies advanced optimizers (e.g. RMSProp, L-BFGS), regularization techniques, and understands tradeoffs. Can interpret loss surfaces and convergence behavior.","Designs custom loss functions and optimization strategies. Understands optimization challenges like saddle points, vanishing gradients, and convergence instability.",Innovates new optimization approaches or techniques. Educates teams on convergence theory and empirical tuning best practices. Bridges theory and production performance.,,,,
Data Preparation & Feature Engineering,Data Cleaning,Aware that data often has issues like missing values or duplicates but lacks understanding of how to handle them.,"Can identify and correct simple issues (e.g. missing data, outliers, formatting inconsistencies) using tools like pandas or SQL.","Understands and applies domain-informed strategies for imputing, filtering, and validating data. Tracks data quality metrics.","Designs scalable, repeatable cleaning pipelines. Anticipates downstream effects of data quality on models.","Leads data hygiene practices across teams. Establishes standards, mentors others, and contributes to tooling or policy for data integrity in ML.",,,,
,Feature Extraction,"Understands that raw data must be transformed into usable input, but unsure how or why.","Can use built-in methods to extract basic features (e.g., text n-grams, image pixels, timestamps).","Designs custom features from structured and unstructured data (e.g., aggregation, parsing, embeddings). Can justify feature choices.",Builds reusable feature generation frameworks. Balances complexity vs. model interpretability.,Pioneers novel feature representations and extraction methods. Guides teams in feature engineering for new problem domains.,,,,
,Feature Selection,Aware that not all features are useful but lacks ability to identify or remove irrelevant ones.,"Uses basic filtering techniques (e.g., correlation thresholding, variance) to reduce features.","Applies techniques like recursive feature elimination, regularization-based selection, and information gain.",Evaluates and automates feature selection strategies to prevent overfitting and boost generalization.,"Develops and validates custom feature scoring methods. Advises teams on balancing performance, interpretability, and compute cost.",,,,
,Normalization & Encoding,"Knows that data needs to be formatted but is unsure how (e.g., categorical values, scales).","Applies techniques like min-max scaling, z-score standardization, one-hot encoding.",Selects appropriate scaling and encoding methods based on model and data type. Handles unseen categories and leakage issues.,"Designs robust preprocessing pipelines (e.g., via sklearn Pipeline, Spark transformers). Balances numerical stability with model assumptions.",Educates others on best practices. Develops or adapts encoding and scaling strategies for novel or large-scale data contexts.,,,,
,Dimensionality Reduction,Aware that too many features can hurt model performance but unfamiliar with reduction techniques.,Can apply basic techniques like PCA with default settings using libraries.,"Understands and selects methods like PCA, t-SNE, UMAP, or autoencoders based on data and task. Can interpret reduced spaces.","Uses dimensionality reduction for interpretability, visualization, or compression. Understands trade-offs and implications.","Designs or evaluates new dimensionality reduction approaches. Mentors others in using these techniques for feature selection, exploration, and model optimization.",,,,
Model Development,Regression Modeling,Recognizes that regression predicts numeric outcomes but has no hands-on experience.,Can fit and evaluate linear regression models using libraries like scikit-learn. Understands concepts like coefficients and residuals.,"Uses advanced regression methods (e.g. ridge, lasso, polynomial). Understands assumptions, multicollinearity, and interprets metrics like RMSE and R².","Designs regression pipelines, handles feature interaction, and addresses overfitting. Explains results to technical and non-technical audiences.",Develops novel regression approaches or tunes architectures for complex tasks. Trains others and establishes modeling standards for regression problems.,,,,
,Classification Modeling,Aware that classification predicts categories. No real modeling experience.,"Can train simple classifiers (e.g. logistic regression, decision tree) and interpret outputs like predicted classes.","Applies and compares multiple classifiers (e.g. random forest, SVM, XGBoost). Understands class imbalance, precision/recall tradeoffs, and ROC/AUC.","Optimizes pipelines, calibrates classifiers, and handles edge cases (e.g., multilabel, ordinal). Integrates model explainability tools.","Innovates on classification techniques for new domains. Establishes classifier evaluation frameworks and mentors others on robust, fair model design.",,,,
,Clustering Techniques,Understands that clustering groups data but doesn't know how it works or why it’s useful.,Uses simple clustering algorithms (e.g. K-means) to explore structure in data. Tunes basic parameters like number of clusters.,"Applies a range of methods (e.g. DBSCAN, hierarchical, GMM). Evaluates using silhouette score, inertia, or domain-informed labeling.","Selects clustering methods based on data shape, scale, and density. Builds interpretable, repeatable workflows for unsupervised tasks.","Designs custom similarity metrics or clustering algorithms. Leads clustering strategy for exploratory or production use, mentoring others in unsupervised ML.",,,,
,Deep Learning (MLPs),Has heard of neural networks. No practical experience building or using one.,Can train a basic feedforward network (MLP) for a supervised task using frameworks like TensorFlow or PyTorch. Understands the concept of layers and activation functions.,"Designs MLP architectures, tunes hyperparameters, and applies best practices (e.g. dropout, batch norm). Understands backpropagation and vanishing gradients.","Tailors architectures to domains (e.g., tabular, text). Integrates MLPs into larger ML systems. Troubleshoots training instability and performance bottlenecks.",Advances MLP usage in novel contexts or architectures. Mentors others and contributes to reusable components or learning frameworks.,,,,
,Reinforcement Learning,Aware that RL involves agents and environments but lacks working knowledge or intuition.,Can run simple RL examples (e.g. cart-pole with Q-learning or DQN). Understands the reward/policy/value loop.,"Implements RL algorithms, tunes reward functions, and applies RL to basic problems. Understands exploration vs. exploitation and convergence.","Applies deep RL in complex environments (e.g., continuous action spaces, simulators). Evaluates stability, sample efficiency, and policy performance.",Researches or innovates in RL algorithms. Leads experimentation with RL in real-world systems and mentors others on long-horizon learning strategies.,,,,
Model Evaluation & Diagnostics,Evaluation Metrics,Recognizes that models need to be evaluated but is unfamiliar with specific metrics.,"Can compute basic metrics like accuracy, precision, recall, or RMSE using libraries.","Understands when and why to use different metrics based on problem type (e.g., classification vs regression).",Selects and justifies appropriate metrics for domain-specific tasks. Incorporates multiple metrics for robust evaluation.,"Defines new or composite metrics, educates teams on best practices, and sets standards for evaluation across projects.",,,,
,Cross-Validation,Aware that cross-validation helps improve generalization but hasn’t applied it.,Can implement simple k-fold or train/test split cross-validation using libraries.,"Understands different CV techniques (e.g., stratified, LOOCV) and applies them appropriately.","Integrates CV into pipelines, handles data leakage concerns, and interprets variance in results.",Designs robust evaluation schemes for complex or time-series data. Coaches others on validation design and pitfalls.,,,,
,Error Analysis,Knows that model errors exist but lacks a framework to analyze them.,Can identify misclassified or high-error examples manually.,Analyzes patterns in errors to find model weaknesses or data quality issues.,"Structures iterative error analysis loops to inform data cleaning, feature updates, or model redesigns.","Leads teams in systematic error analysis, linking it to business KPIs and continuous improvement processes.",,,,
,Model Bias & Fairness,Aware that models can be biased but lacks practical understanding.,"Can identify basic types of bias (e.g., class imbalance) and compute group-based metrics like demographic parity.",Understands causes of algorithmic bias and interprets fairness metrics within context.,"Applies fairness-aware training, post-processing, or auditing techniques. Navigates ethical tradeoffs.",Sets organizational standards for fairness. Leads efforts on ethical ML and regulatory compliance. Educates others on bias mitigation.,,,,
,Calibration,Has heard of model calibration but doesn’t know what it means or when it's used.,Can generate and interpret calibration plots or reliability diagrams.,Understands how to assess and improve calibration using techniques like Platt scaling or isotonic regression.,"Applies calibration in production workflows (e.g., probability thresholds, risk scoring) and evaluates model confidence systematically.","Develops calibration-aware models, instructs others on uncertainty quantification, and innovates in trust-building techniques.",,,,
Model Optimization & Tuning,Hyperparameter Tuning,Aware that models have hyperparameters but doesn’t know what or how to tune them.,Can modify hyperparameters manually and run simple grid searches.,Understands the impact of key hyperparameters and applies grid/random search effectively.,"Uses automated search strategies (e.g., Bayesian, Optuna), interprets tuning results critically.","Designs advanced tuning strategies, custom search spaces, and optimizes tuning pipelines across projects.",,,,
,Regularization,Has heard of overfitting and regularization but doesn’t know how they work.,Can apply L1/L2 regularization using library defaults.,Understands how regularization affects model complexity and generalization; can tune penalties effectively.,"Chooses and configures regularization strategies (e.g., dropout, elastic net) based on model and dataset.",Develops regularization schemes for novel models or domains; teaches others how to balance bias-variance trade-offs.,,,,
,Model Selection,Recognizes that different models exist but doesn’t know how to choose between them.,"Can compare models using simple metrics (e.g., accuracy, RMSE).","Uses evaluation metrics, validation results, and task requirements to select suitable models.","Balances interpretability, performance, and deployment needs when selecting models.","Leads architecture decisions across projects, drives innovation by proposing new model classes or paradigms.",,,,
,Ensembling,Is vaguely aware that combining models can improve performance.,Can implement basic ensembles like majority voting or averaging.,"Understands bagging, boosting, and stacking; selects ensemble methods based on goals and data.",Designs and tunes ensembles that improve robustness and generalization; integrates ensemble workflows into pipelines.,Develops ensemble strategies for critical applications; teaches ensembling trade-offs and failure modes to others.,,,,
,Imbalance Handling,Aware that class imbalance can hurt model performance but doesn’t know what to do.,Can apply basic techniques like oversampling or class weighting.,"Diagnoses imbalance problems using metrics and distributions; applies SMOTE, stratification, or cost-sensitive training.",Builds custom imbalance strategies depending on business impact and context; integrates mitigation in training pipelines.,Drives fairness and imbalance resolution policies; mentors others on building resilient models for rare-event or skewed-data problems.,,,,
"Productionalization, Operation, & Model Lifecycle",Model Serialization,Understands that trained models can be saved but not how or why.,"Can save and load models using built-in library methods (e.g., joblib, pickle, torch.save).",Applies serialization formats appropriate to deployment context and handles versioning.,"Builds reusable serialization modules; considers model portability, compatibility, and security.","Defines organization-wide serialization standards, tools, and compatibility layers; trains others on best practices.",,,,
,Model Deployment,"Knows models must be deployed to be used, but unfamiliar with methods.","Can deploy a model locally or via a simple API (e.g., Flask or FastAPI).","Uses model serving frameworks (e.g., MLflow, TorchServe, SageMaker) and integrates with backend systems.","Designs scalable, resilient deployment strategies (e.g., containerized microservices, serverless).",Leads architecture for ML platforms; standardizes deployment pipelines; mentors teams on production ML practices.,,,,
,CI/CD for ML,"Aware that automation is used in software, but unsure how it applies to ML.",Can trigger retraining or tests manually using scripts or notebooks.,"Implements ML-specific CI/CD flows (e.g., automated retraining, testing, linting, model validation).","Integrates CI/CD into MLOps pipelines with branch-based triggers, model registry, and approvals.","Architects CI/CD systems for reproducibility, auditability, and collaboration across ML lifecycle. Guides others in DevOps/MLOps fusion.",,,,
,Model Monitoring,Understands that deployed models may drift or fail but doesn’t monitor them.,Can log basic metrics and usage statistics post-deployment.,"Monitors performance, data drift, and service health using alerts and dashboards.","Builds automated feedback loops, integrates observability tooling (e.g., Prometheus, Grafana, Evidently).","Leads monitoring architecture across teams; formalizes accountability frameworks (e.g., SLA/SLOs) and incident response for ML.",,,,
,Retraining Strategy,Knows models need occasional updates but has no plan for it.,Can manually retrain a model when performance declines.,"Sets up retraining triggers (e.g., periodic, drift-based) and maintains retraining scripts.","Automates retraining with validation gates, rollback options, and metadata tracking.","Designs adaptive learning systems, owns lifecycle governance, and coaches teams on sustainable model evolution.",,,,
Programming & Libraries for ML,Python Programming,Can read simple Python code; struggles to write or debug.,"Writes basic scripts, uses functions, and controls flow for data tasks.","Writes modular, readable code with exception handling and logging; uses libraries effectively.","Follows software engineering practices (e.g., unit testing, packaging, typing) for ML pipelines.","Develops shared codebases and internal packages; mentors others on performance, design, and maintainability.",,,,
,NumPy & Pandas,Can load data using Pandas but struggles with transformations or vectorization.,"Performs basic wrangling, indexing, and aggregations; uses NumPy for simple math.","Uses advanced operations (e.g., broadcasting, groupby, joins, reshaping) effectively in pipelines.","Optimizes code using vectorized operations, memory management, and chunking.",Trains others in high-performance numerical computing; contributes reusable data utilities or wrappers.,,,,
,scikit-learn,"Aware of its use in ML, but unfamiliar with APIs.","Trains models using .fit(), evaluates with .score(), and applies transformations.","Uses pipelines, model selection, preprocessing, and cross-validation workflows effectively.","Extends estimators, writes custom transformers, integrates with production workflows.","Advocates for standardization; mentors others in scalable, composable scikit-learn design patterns.",,,,
,Deep Learning Frameworks,"Knows names (e.g., PyTorch, TensorFlow) but unsure how to use them.","Can build simple MLPs or CNNs using a high-level API (e.g., nn.Sequential, Keras).",Writes custom models and training loops; uses GPU acceleration and data loaders.,"Optimizes training with callbacks, scheduling, and mixed-precision; integrates with production tooling.","Builds reusable frameworks, mentors on trade-offs across DL libraries, and contributes to shared model infrastructure.",,,,
,Notebook prototyping,Uses notebooks sporadically with poor structure or output management.,Runs linear prototypes with inline plots and print debugging.,"Uses versioned, well-commented notebooks for reproducible experiments.","Structures notebooks with parameterization, exports outputs, and integrates with scripts or pipelines.","Promotes best practices (e.g., modularization, reproducibility); maintains shared templates and reviewable notebooks.",,,,
ML Systems & Scalability,Mini-batch & GPU Training,Understands that ML training can be slow and GPUs can help.,Can configure mini-batch sizes and enable GPU use in a framework like PyTorch or TensorFlow.,"Tunes batch sizes, leverages GPU memory efficiently, uses data loaders and augmentation pipelines.","Profiles and optimizes GPU throughput, resolves bottlenecks, and uses multiple GPUs effectively.","Designs scalable training routines, selects appropriate hardware, and teaches teams efficient deep learning practices.",,,,
,Distributed Training,Knows large models can be trained across machines but lacks practical experience.,"Uses high-level APIs (e.g., DataParallel, Accelerate, tf.distribute) for multi-GPU or node setups.","Implements training across nodes using Horovod, PyTorch DDP, or custom RPC backends.","Balances load, manages communication overhead, and ensures fault tolerance in large-scale jobs.",Architects and oversees distributed training infrastructure across projects; mentors teams on cost/performance trade-offs.,,,,
,Pipeline Integration,Understands that ML is part of a broader system but sees it in isolation.,Can save/load models and integrate them into basic workflows via scripts or APIs.,"Builds training/inference steps as modular components in orchestrated workflows (e.g., Airflow, MLflow, SageMaker Pipelines).","Connects ML components to upstream/downstream systems (e.g., ETL, alerts, APIs) and handles dependencies.","Leads platform integration strategy; standardizes ML pipeline design; mentors teams on resilient, maintainable workflows.",,,,
,Resource Optimization,Aware that compute is expensive but does not manage usage.,Minimizes memory or disk use manually; uses smaller batch sizes or simpler models.,"Applies profiling tools, quantization, pruning, or model distillation techniques.","Automates resource-efficient workflows, balances cost-performance, and aligns with infrastructure constraints.",Develops resource budgeting frameworks; drives culture of efficient computing and trains others to optimize at scale.,,,,
,Serving Infrastructure,"Knows models can be deployed, but not how they are served in production.","Deploys models using basic APIs or frameworks like Flask, FastAPI, or Streamlit.","Uses model serving solutions (e.g., TorchServe, TensorFlow Serving, BentoML) and handles REST/gRPC endpoints.","Designs scalable and fault-tolerant serving systems with A/B testing, canary deployments, and autoscaling.",Leads ML platform infrastructure; defines organization-wide best practices for serving and maintains critical production deployments.,,,,
Use Cases & Application Design,Problem Framing,Struggles to distinguish between a data task and a business problem.,"Identifies if a problem is classification, regression, or clustering; starts defining goals.",Translates business needs into ML problems with clearly scoped objectives and constraints.,"Frames ambiguous problems into tractable ML tasks, including evaluation criteria and feasibility.",Guides cross-functional teams in framing strategic ML initiatives; mentors others in problem scoping under uncertainty.,,,,
,Business Metrics Mapping,Unaware of the relationship between model outputs and business value.,"Associates common metrics (e.g., accuracy, MSE) with product impact at a basic level.","Aligns model metrics to business KPIs, selects thresholds based on cost-benefit trade-offs.","Designs custom metrics reflecting real-world performance (e.g., churn saved, revenue impact).",Advises stakeholders on long-term metric strategies; trains teams on goal-oriented metric design.,,,,
,Use Case Pioritization,Treats all ML opportunities as equal; lacks context for decision-making.,Understands basic factors like data availability and implementation difficulty.,"Prioritizes ML use cases based on impact, feasibility, risk, and resourcing.",Leads cross-team roadmapping; balances short-term wins with long-term investments.,Builds ML portfolio strategies; mentors product and engineering teams on data-driven prioritization frameworks.,,,,
,Ethical Impact Analysis,Unaware of ML’s ethical or social implications.,"Acknowledges possible risks (e.g., bias, privacy) but doesn’t analyze them.","Identifies potential ethical concerns and designs mitigation strategies (e.g., anonymization, fairness audits).","Collaborates on cross-functional reviews, supports explainability, and integrates compliance needs.",Champions responsible AI practices; develops frameworks and training for ethical ML design across the organization.,,,,
ML Project Management,Identifying ML Project Conditions,Struggles to determine if ML is appropriate for a problem.,Recognizes when labeled data and predictive needs suggest an ML approach.,"Evaluates technical feasibility (data volume, quality), business relevance, and risks.","Performs thorough opportunity assessments including legal, ethical, and stakeholder alignment.","Leads organization-wide intake for ML initiatives; trains teams to assess readiness, risk, and opportunity systematically.",,,,
,Project Planning & Estimation,Unfamiliar with timelines or resources needed for ML tasks.,"Can list stages (e.g., data collection, training, deployment) but struggles with accurate estimates.","Builds realistic timelines including iteration cycles, data dependencies, and handoff points.","Manages risk buffers, coordinates with multiple stakeholders, and adapts plans as data evolves.","Leads ML portfolio management; institutionalizes planning practices for high-impact, reliable delivery.",,,,
,Reporting Outcomes,"Focuses only on technical metrics (e.g., accuracy); struggles to communicate value.",Prepares basic reports with performance plots and summary metrics.,"Communicates results in stakeholder language, connects to KPIs and decisions.","Builds dashboards, presents trade-offs and uncertainties clearly, and guides decision-making.",Coaches teams in outcome storytelling; advises leadership on results interpretation and strategic implications.,,,,
